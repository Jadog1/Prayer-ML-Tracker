{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy.orm import scoped_session, Session\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.repo.orm import OpenPool, PrayerRequestORM\n",
    "import tqdm\n",
    "load_dotenv()\n",
    "pg_uri = os.environ.get('PRAYERS_PG_DATABASE_URL')\n",
    "\n",
    "pool: scoped_session[Session] = OpenPool(pg_uri)\n",
    "\n",
    "class Backfill(ABC):\n",
    "    @abstractmethod\n",
    "    def filter(self, session: Session)->list[PrayerRequestORM]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_fields(self, ormRequest: PrayerRequestORM):\n",
    "        pass\n",
    "\n",
    "class NewFill(ABC):\n",
    "    @abstractmethod\n",
    "    def filter(self, session: Session)->list:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def insert(self, session: Session, item):\n",
    "        pass\n",
    "\n",
    "# Backfill the prayer request table\n",
    "# Use tqdm to show progress\n",
    "def PrayerRequestBackfill(backfill: Backfill):\n",
    "    with pool() as session:\n",
    "        results = backfill.filter(session)\n",
    "        for ormRequest in tqdm.tqdm(results):\n",
    "            backfill.update_fields(ormRequest, session)\n",
    "        session.commit()\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.3.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 900/900 [03:19<00:00,  4.51it/s] \n"
     ]
    }
   ],
   "source": [
    "from src.models.models import BibleEmbeddings, ClassifierModels, EmbeddingResult, Embeddings\n",
    "from src.repo.prayerRequests import PrayerRequestRepoImpl\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "gteBase = SentenceTransformer('thenlper/gte-base')\n",
    "\n",
    "embedding_model = Embeddings()\n",
    "# bible_model = BibleEmbeddings()\n",
    "classifier_models = ClassifierModels()\n",
    "repo = PrayerRequestRepoImpl(pool, embedding_model, None)\n",
    "\n",
    "class PrayerTopicsBackfill(Backfill):\n",
    "    def filter(self, session: Session)->list[PrayerRequestORM]:\n",
    "        return session.query(PrayerRequestORM).all()\n",
    "\n",
    "    def update_fields(self, ormRequest: PrayerRequestORM, session: Session):\n",
    "        gte_base = gteBase.encode(ormRequest.request)\n",
    "        embedding = EmbeddingResult(gte_base, None)\n",
    "        repo._rebuild_prayer_topics(session, ormRequest.id, embedding)\n",
    "\n",
    "PrayerRequestBackfill(PrayerTopicsBackfill())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 778/778 [03:53<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.models.models import ClassifierModels\n",
    "\n",
    "classifiers = ClassifierModels()\n",
    "\n",
    "class BackfillSentiment(Backfill):\n",
    "    def filter(self, session: Session)->list[PrayerRequestORM]:\n",
    "        return session.query(PrayerRequestORM).filter(\n",
    "            PrayerRequestORM.sentiment_analysis == None ).all()\n",
    "\n",
    "    def update_fields(self, ormRequest: PrayerRequestORM):\n",
    "        result = classifiers.classify(ormRequest.request)\n",
    "        ormRequest.sentiment_analysis = result['sentiment']\n",
    "        ormRequest.emotion_roberta = result['emotion']\n",
    "\n",
    "backfiller = BackfillSentiment()\n",
    "# PrayerRequestBackfill(backfiller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.repo.orm import BibleTopicORM, TopicORM, BibleTopicsORM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "gteBase = SentenceTransformer('thenlper/gte-base')\n",
    "\n",
    "def InsertFill(backfill: NewFill):\n",
    "    with pool() as session:\n",
    "        results = backfill.filter(session)\n",
    "        # Loop over index and item with tqdm\n",
    "        for i, item in tqdm.tqdm(results.iterrows()):\n",
    "            backfill.insert(session, item, i)\n",
    "        session.commit()\n",
    "        session.close()\n",
    "\n",
    "class TagsFill(NewFill):\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "\n",
    "    def filter(self, session: Session)->list:\n",
    "        unique_topics = pd.read_csv('../src/scraped_data/topics.csv')\n",
    "        self.embeddings = gteBase.encode(unique_topics['topic'], show_progress_bar=True)\n",
    "        return unique_topics\n",
    "\n",
    "    def insert(self, session: Session, item: pd.Series, i: int):\n",
    "        topic = item['topic']\n",
    "        embedding = self.embeddings[i]\n",
    "        tag = TopicORM(\n",
    "            name=topic,\n",
    "            gte_base_embedding=embedding\n",
    "        )\n",
    "        session.add(tag)\n",
    "\n",
    "class BibleTagsFill(NewFill):\n",
    "    def filter(self, session: Session)->list:\n",
    "        niv_topics = pd.read_csv('../src/scraped_data/NIV_tags.csv')\n",
    "        niv_topics['verse_numbers'] = niv_topics['verse_numbers'].apply(lambda x: eval(x))\n",
    "        niv_topics['verse_start'] = niv_topics['verse_numbers'].apply(lambda x: x[0])\n",
    "        niv_topics['verse_end'] = niv_topics['verse_numbers'].apply(lambda x: x[1] if len(x) > 1 else None)\n",
    "        niv_topics[\"verse_end\"] = niv_topics[\"verse_end\"].replace({np.nan: None})\n",
    "        niv_topics['tags'] = niv_topics['tags'].apply(lambda x: eval(x))\n",
    "        \n",
    "        topic_ids = {}\n",
    "        allTopics = session.query(TopicORM).all()\n",
    "        for topic in allTopics:\n",
    "            topic_ids[topic.name] = topic.id\n",
    "        self.topic_ids = topic_ids\n",
    "        self.embeddings = gteBase.encode(niv_topics['verse_text'], show_progress_bar=True)\n",
    "        return niv_topics\n",
    "\n",
    "    def insert(self, session: Session, item: pd.Series, i:int):\n",
    "        bibleTopic = BibleTopicORM(\n",
    "            book = item['book'],\n",
    "            chapter = item['chapter'],\n",
    "            verse_start = item['verse_start'],\n",
    "            verse_end = item['verse_end'],\n",
    "            content = item['verse_text'],\n",
    "            gte_base_embedding = self.embeddings[i]\n",
    "        )\n",
    "        session.add(bibleTopic)\n",
    "        session.commit()\n",
    "        session.refresh(bibleTopic)\n",
    "        for tag in item['tags']:\n",
    "            topic_id = self.topic_ids[tag]\n",
    "            bibleTopics = BibleTopicsORM(\n",
    "                topic_id = topic_id,\n",
    "                bible_topic_id = bibleTopic.id\n",
    "            )\n",
    "            session.add(bibleTopics)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:01<00:00,  2.91it/s]\n",
      "159it [00:00, 3526.97it/s]\n"
     ]
    }
   ],
   "source": [
    "topicBackfiller = TagsFill()\n",
    "InsertFill(topicBackfiller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 45/45 [01:55<00:00,  2.56s/it]\n",
      "1419it [00:23, 60.32it/s]\n"
     ]
    }
   ],
   "source": [
    "bibleTagsBackfill = BibleTagsFill()\n",
    "InsertFill(bibleTagsBackfill)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
