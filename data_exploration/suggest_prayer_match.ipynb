{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.repo.orm import OpenPool, PrayerRequestORM\n",
    "from src.dto.prayerRequests import PrayerRequest\n",
    "load_dotenv()\n",
    "import os\n",
    "import pandas as pd\n",
    "pg_uri = os.environ.get('PRAYERS_PG_DATABASE_URL')\n",
    "pool = OpenPool(pg_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "from datetime import datetime, UTC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class FeatureBuilder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build_preprocess(self, data: list[dict])->pd.DataFrame:\n",
    "        today = datetime.now(UTC)\n",
    "        for obj in data:\n",
    "            obj['dayLength'] = (today - obj['created_at']).days\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def build_postprocess(self, paired_components: np.ndarray, use_day_feature = True, use_similarity_feature = True, has_predictive=True)->np.ndarray:\n",
    "        processed = []\n",
    "        for contact_group in paired_components:\n",
    "            for pairs in contact_group:\n",
    "                left_pair = pairs[0]\n",
    "                right_pair = pairs[1]\n",
    "                left_vector: np.ndarray = left_pair[0]\n",
    "                right_vector: np.ndarray = right_pair[0]\n",
    "                left_days = left_pair[1]\n",
    "                right_days = right_pair[1]\n",
    "                similarity = cosine(left_vector, right_vector)\n",
    "                averaged_vector = (left_vector + right_vector) / 2.0\n",
    "\n",
    "                extra_features = self.build_y_feature(left_pair, right_pair, has_predictive)\n",
    "                if use_day_feature:\n",
    "                    extra_features.insert(0, right_days)\n",
    "                    extra_features.insert(0, left_days)\n",
    "                if use_similarity_feature:\n",
    "                    extra_features.insert(0, similarity)\n",
    "                new_feature_set = np.concatenate([averaged_vector, extra_features])\n",
    "                processed.append(new_feature_set)\n",
    "\n",
    "        return np.array(processed)\n",
    "    \n",
    "    def build_postprocess2(self, paired_components: np.ndarray, use_day_feature = True, use_similarity_feature = True, has_predictive=True)->np.ndarray:\n",
    "        processed = []\n",
    "        for contact_group in paired_components:\n",
    "            for pairs in contact_group:\n",
    "                left_pair = pairs[0]\n",
    "                right_pair = pairs[1]\n",
    "                left_vector: np.ndarray = left_pair[0]\n",
    "                right_vector: np.ndarray = right_pair[0]\n",
    "                left_days = left_pair[1]\n",
    "                right_days = right_pair[1]\n",
    "                similarity = cosine(left_vector, right_vector)\n",
    "\n",
    "                extra_features = self.build_y_feature(left_pair, right_pair, has_predictive)\n",
    "                if use_day_feature:\n",
    "                    extra_features.insert(0, right_days)\n",
    "                    extra_features.insert(0, left_days)\n",
    "                if use_similarity_feature:\n",
    "                    extra_features.insert(0, similarity)\n",
    "                new_feature_set = np.concatenate([left_vector, right_vector, extra_features])\n",
    "                processed.append(new_feature_set)\n",
    "\n",
    "        return np.array(processed)\n",
    "    \n",
    "    def build_y_feature(self, left_pair, right_pair, has_predictive:bool)->list:\n",
    "        if not has_predictive:\n",
    "            return []\n",
    "        y = False\n",
    "        if left_pair[2] == right_pair[2] and not np.isnan(left_pair[2]):\n",
    "            y = True\n",
    "        return [y]\n",
    "                \n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = [\"dayLength\"]\n",
    "\n",
    "    def fit_transform(self, data: list[dict]):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        self.scaler.fit(df[self.columns])\n",
    "\n",
    "    def transform(self, df: pd.DataFrame)->np.ndarray:\n",
    "        self.scaler.transform(df[self.columns])\n",
    "        df[\"embedding\"].to_numpy()\n",
    "        # nparray = df.apply(lambda x: np.append(x[\"embedding\"], x[\"dayLength\"]), axis=1).to_numpy()\n",
    "            \n",
    "        return df[[\"embedding\", \"dayLength\", \"link_id\", \"prayer_request\"]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prayer_request</th>\n",
       "      <th>embedding</th>\n",
       "      <th>link_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>contact_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mom is thinking she wants to move to Tennessee...</td>\n",
       "      <td>[-0.009760048, -0.005248226, 0.0009992049, -0....</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2024-05-20 23:19:10.768122+00:00</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish ministry has been twice a month gather...</td>\n",
       "      <td>[-0.014935532, -0.032861583, 0.012076679, 0.00...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2024-04-15 23:14:53.639172+00:00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      prayer_request   \n",
       "0  Mom is thinking she wants to move to Tennessee...  \\\n",
       "1  Spanish ministry has been twice a month gather...   \n",
       "\n",
       "                                           embedding  link_id   \n",
       "0  [-0.009760048, -0.005248226, 0.0009992049, -0....    182.0  \\\n",
       "1  [-0.014935532, -0.032861583, 0.012076679, 0.00...    175.0   \n",
       "\n",
       "                        created_at  contact_id  \n",
       "0 2024-05-20 23:19:10.768122+00:00          29  \n",
       "1 2024-04-15 23:14:53.639172+00:00          28  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_requests = []\n",
    "with pool() as session:\n",
    "    prayer_requests = session.query(PrayerRequestORM).all()\n",
    "    for request in prayer_requests:\n",
    "        if request.request == \"\":\n",
    "            continue\n",
    "        requestObject = {\n",
    "            \"prayer_request\": request.request,\n",
    "            \"embedding\": request.gte_base_embedding,\n",
    "            \"link_id\": request.link_id,\n",
    "            \"created_at\": request.created_at,\n",
    "            \"contact_id\": request.contact_id\n",
    "        }\n",
    "        all_requests.append(requestObject)\n",
    "\n",
    "df = pd.DataFrame(all_requests)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contact_groups = {}\n",
    "feature_builder = FeatureBuilder()\n",
    "preprocessor = Preprocessor()\n",
    "preprocess_features = feature_builder.build_preprocess(all_requests)\n",
    "preprocessed = preprocessor.fit_transform(preprocess_features)\n",
    "\n",
    "for i in range(len(preprocessed)):\n",
    "    if all_requests[i]['contact_id'] not in contact_groups:\n",
    "        contact_groups[all_requests[i]['contact_id']] = []\n",
    "    contact_groups[all_requests[i]['contact_id']].append(preprocessed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "paired_components = []\n",
    "for index in contact_groups:\n",
    "    group = contact_groups[index]\n",
    "    paired_components.append(list(combinations(group, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25650"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_feature_set = feature_builder.build_postprocess(paired_components, use_day_feature=True, use_similarity_feature=True)\n",
    "# final_feature_set = feature_builder.build_postprocess2(paired_components, use_day_feature=False, use_similarity_feature=False)\n",
    "len(final_feature_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = final_feature_set[:,-1]\n",
    "X = final_feature_set[:, :-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9907894736842106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9884990253411307"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(random_state=42, learning_rate=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.335164574506615"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores seem suspicious, and so do the weights. Seems like a classic case of overfitting\n",
    "# Would like to experiment in production\n",
    "model.feature_importances_.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Family is continuing to improve',\n",
       "        'An update on my family, they are getting better']], dtype=object)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.repo.orm import ContactORM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datetime import datetime, UTC\n",
    "import pandas as pd\n",
    "contactNameToId = {}\n",
    "with pool() as session:\n",
    "    contacts = session.query(ContactORM).all()\n",
    "    for contact in contacts:\n",
    "        contactNameToId[contact.name] = contact.id\n",
    "\n",
    "testUserContactID = contactNameToId['Test User']\n",
    "\n",
    "gte_transformer = SentenceTransformer(\"thenlper/gte-base\")\n",
    "\n",
    "def ImitateUser_FindRelated(contactID : int, request : str)->np.ndarray:\n",
    "    embeddings = gte_transformer.encode(request, convert_to_numpy=True)\n",
    "    created_at = datetime.now(UTC)\n",
    "    link_id = np.nan\n",
    "    imitate_request = {\n",
    "        \"prayer_request\": request,\n",
    "        \"embedding\": embeddings,\n",
    "        \"link_id\": link_id,\n",
    "        \"created_at\": created_at,\n",
    "        \"contact_id\": contactID\n",
    "    }\n",
    "    preprocess_features = feature_builder.build_preprocess([imitate_request])\n",
    "    preprocessed = preprocessor.transform(preprocess_features)\n",
    "    paired_components = []\n",
    "    for element in contact_groups[contactID]:\n",
    "        paired_components.append((preprocessed[0], element))\n",
    "    final_features = feature_builder.build_postprocess([paired_components], has_predictive=False)\n",
    "    predictions = model.predict(final_features)\n",
    "    indexes = np.where(predictions == 1)\n",
    "    if len(indexes) == 0:\n",
    "        return []\n",
    "    return np.array(paired_components)[indexes][:, :,3]\n",
    "\n",
    "related_requests = ImitateUser_FindRelated(testUserContactID, \"Family is continuing to improve\")\n",
    "related_requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
