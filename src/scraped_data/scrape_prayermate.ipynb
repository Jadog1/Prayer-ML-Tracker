{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Program Files\\\\Python312\\\\python312.zip', 'c:\\\\Program Files\\\\Python312\\\\DLLs', 'c:\\\\Program Files\\\\Python312\\\\Lib', 'c:\\\\Program Files\\\\Python312', '', 'C:\\\\Users\\\\jadog\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\jadog\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jadog\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jadog\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\Pythonwin', 'c:\\\\Program Files\\\\Python312\\\\Lib\\\\site-packages', '../..']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadog\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jadog\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Go back to parent\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "print(sys.path)\n",
    "\n",
    "from src.models.models import ClassifierModels, Embeddings\n",
    "from src.repo.orm import OpenPool\n",
    "from src.repo.prayerRequests import PrayerRequestRepoImpl\n",
    "from src.repo.contacts import ContactRepoImpl\n",
    "from src.dto.groups import Group\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "pg_uri = os.environ.get('PRAYERS_PG_DATABASE_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model for prayer type classification\n",
      "[Errno 2] No such file or directory: 'C:\\\\Users\\\\jadog\\\\Documents\\\\Code\\\\Prayer-ML-Tracker\\\\src\\\\models\\\\..\\\\..\\\\cache\\\\prayers\\\\prayer_or_praise.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Replace Account with the actual class name for the user model\n",
    "user_id = 1\n",
    "pool = OpenPool(pg_uri)\n",
    "embedding_model = Embeddings()\n",
    "classifier_models = ClassifierModels()\n",
    "prayerRepo = PrayerRequestRepoImpl(pool, embedding_model, classifier_models)\n",
    "contactRepo = ContactRepoImpl(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>subject</th>\n",
       "      <th>prayerRequest</th>\n",
       "      <th>archivedDate</th>\n",
       "      <th>stackGroup</th>\n",
       "      <th>createdDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Monday Bible Study</td>\n",
       "      <td>Jadon</td>\n",
       "      <td>Prayers for Melissa cousin whose wedding got c...</td>\n",
       "      <td>None</td>\n",
       "      <td>ed78b3de-a628-4f17-bfb2-217ed3e3f6df</td>\n",
       "      <td>2023-11-20 19:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Monday Bible Study</td>\n",
       "      <td>Jadon</td>\n",
       "      <td>Praise for getting focused over weekend on lea...</td>\n",
       "      <td>None</td>\n",
       "      <td>49c4a9cb-5129-4411-b167-488f44e2a49d</td>\n",
       "      <td>2023-11-20 19:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category subject  \\\n",
       "475  Monday Bible Study   Jadon   \n",
       "476  Monday Bible Study   Jadon   \n",
       "\n",
       "                                         prayerRequest archivedDate  \\\n",
       "475  Prayers for Melissa cousin whose wedding got c...         None   \n",
       "476  Praise for getting focused over weekend on lea...         None   \n",
       "\n",
       "                               stackGroup         createdDate  \n",
       "475  ed78b3de-a628-4f17-bfb2-217ed3e3f6df 2023-11-20 19:21:00  \n",
       "476  49c4a9cb-5129-4411-b167-488f44e2a49d 2023-11-20 19:22:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "# Load json object, and get the Categories array to use as a dataframe\n",
    "with open('./Prayermate.json') as f:\n",
    "    data = json.load(f)\n",
    "    categories = data['Categories']\n",
    "\n",
    "prayerRequests = []\n",
    "for category in categories:\n",
    "    for subject in category['subjects']:\n",
    "        for prayerRequest in subject['cards']:\n",
    "            prayerRequests.append({\n",
    "                'category': category['name'],\n",
    "                'subject': subject['name'],\n",
    "                'prayerRequest': prayerRequest['text'],\n",
    "                'archivedDate': prayerRequest['archivedDate'] if prayerRequest['archived'] else None,\n",
    "                'stackGroup': prayerRequest['stackGroup'],\n",
    "                'createdDate': prayerRequest['createdDate'],\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(prayerRequests)\n",
    "\n",
    "df['createdDate'] = pd.to_datetime(df['createdDate'])\n",
    "# df['archivedDate'] = pd.to_datetime(df['archivedDate'])\n",
    "# replace pd.NaT with None\n",
    "# df['archivedDate'] = df['archivedDate'].apply(lambda x: None if x is pd.NaT else x)\n",
    "df[df['subject'] == 'Jadon'].head(2)\n",
    "# df[df['subject'] == 'Jadon']['archivedDate'].iloc[0] is pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df['category'].unique()\n",
    "for group in groups:\n",
    "    group = Group().from_dict({'name': group})\n",
    "    contactRepo.save_group(user_id, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dto.contacts import Contact\n",
    "all_groups = contactRepo.get_groups(user_id).to_dataframe()\n",
    "contacts = df.groupby(['category', 'subject']).agg({\n",
    "    'createdDate': 'min'\n",
    "}).reset_index()\n",
    "for index, row in contacts.iterrows():\n",
    "    group = all_groups[all_groups['name'] == row['category']]\n",
    "    group_id = group['id'].values[0]\n",
    "    contact = Contact().from_dict({'name': row['subject'], 'account_id': user_id, 'created_at': row['createdDate']})\n",
    "    contactRepo.save_contact(user_id, contact, group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dto.prayerRequests import PrayerRequest, PrayerRequests\n",
    "from src.dto.link import Link\n",
    "from src.repo.orm import LinkORM\n",
    "# Create a dataframe to map stackGroup to a unique integer link_id, order by stackGroup\n",
    "# Also create a column count to keep track of the number of prayer requests in each stackGroup\n",
    "stackGroups = df['stackGroup'].unique()\n",
    "stackGroups = pd.DataFrame(stackGroups, columns=['stackGroup']).sort_values(by='stackGroup')\n",
    "stackGroups['count'] = df.groupby('stackGroup').size().reset_index(name='counts')['counts']\n",
    "stackGroups = stackGroups[stackGroups['count'] > 1]\n",
    "stackGroups.reset_index(inplace=True)\n",
    "stackGroups['link_id'] = stackGroups.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pool() as session:\n",
    "    for index, row in stackGroups.iterrows():\n",
    "        link = LinkORM(id=row['link_id'])\n",
    "        session.add(link)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dto.prayerRequests import PrayerRequest, PrayerRequests\n",
    "from src.repo.prayerRequests import PrayerRequestRepoImpl\n",
    "from src.dto.contacts import Contact\n",
    "from src.repo.orm import ContactGroupORM, ContactORM, GroupORM\n",
    "contacts = df.groupby(['category', 'subject']).size().reset_index(name='counts')\n",
    "with pool() as session:\n",
    "    for index, row in df.iterrows():\n",
    "        contactOrm = session.query(ContactGroupORM).filter(ContactORM.name == row['subject'] and GroupORM.name == row['category']).first()\n",
    "        contact_id = contactOrm.id\n",
    "        stackGroupRow = stackGroups[stackGroups['stackGroup'] == row['stackGroup']]\n",
    "        link_id = None if stackGroupRow.empty else int(stackGroupRow['link_id'].values[0])\n",
    "        prayerRequest = PrayerRequest().from_dict({\n",
    "            'contact': {'id': int(contact_id)},\n",
    "            'request': row['prayerRequest'],\n",
    "            'archived_at': row['archivedDate'],\n",
    "            'created_at': row['createdDate'],\n",
    "            'link_id': link_id\n",
    "        })\n",
    "        prayerRepo.save(user_id, prayerRequest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
